import os

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np

# å®šä¹‰BCç­–ç•¥ç½‘ç»œï¼ˆç®€å•MLPï¼‰
class BCPolicy(nn.Module):
    def __init__(self, state_dim=808, action_dim=4): #  state_dim ä»12æ”¹æˆ808ï¼ˆæ ¹æ®ä½ çš„å®é™…ç»´åº¦è°ƒæ•´ï¼‰
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(state_dim, 64),  # è¾“å…¥ï¼š12ç»´çŠ¶æ€
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, action_dim)  # è¾“å‡ºï¼š4ä¸ªåŠ¨ä½œçš„logits
        )

    def forward(self, x):
        return self.net(x)

def load_all_npz_data(data_dir="data2"):
    """
    è¯»å– data ç›®å½•ä¸‹æ‰€æœ‰ .npz æ–‡ä»¶ï¼Œåˆå¹¶ states å’Œ actions ä¸º torch å¼ é‡
    :param data_dir: æ•°æ®ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤ "data"ï¼‰
    :return: åˆå¹¶åçš„ states (torch.float32)ã€actions (torch.long)
    """
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(data_dir):
        raise FileNotFoundError(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼š{data_dir}")

    # å­˜å‚¨æ‰€æœ‰æ–‡ä»¶çš„ states å’Œ actionsï¼ˆå…ˆå­˜ numpy æ•°ç»„ï¼Œæœ€åç»Ÿä¸€è½¬å¼ é‡ï¼Œæ•ˆç‡æ›´é«˜ï¼‰
    all_states = []
    all_actions = []

    # éå† data ç›®å½•ä¸‹æ‰€æœ‰ .npz æ–‡ä»¶
    for filename in os.listdir(data_dir):
        # åªå¤„ç† .npz åç¼€çš„æ–‡ä»¶
        if filename.endswith(".npz"):
            file_path = os.path.join(data_dir, filename)  # å®Œæ•´æ–‡ä»¶è·¯å¾„
            print(f"æ­£åœ¨åŠ è½½ï¼š{file_path}")

            try:
                # åŠ è½½å•ä¸ª npz æ–‡ä»¶
                data = np.load(file_path, allow_pickle=True)  # allow_pickle å…¼å®¹æ—§ç‰ˆæœ¬æ•°æ®

                # æå– states å’Œ actionsï¼ˆç¡®ä¿é”®åæ­£ç¡®ï¼Œä¸ä½ çš„æ–‡ä»¶ä¸€è‡´ï¼‰
                states = data["states"]
                actions = data["actions"]

                # éªŒè¯æ•°æ®æœ‰æ•ˆæ€§ï¼ˆé¿å…ç©ºæ•°æ®æˆ–æ ¼å¼é”™è¯¯ï¼‰
                if len(states) == 0 or len(actions) == 0:
                    print(f"âš ï¸  è·³è¿‡ç©ºæ–‡ä»¶ï¼š{filename}")
                    continue
                if len(states) != len(actions):
                    print(f"âš ï¸  è·³è¿‡æ•°æ®é•¿åº¦ä¸åŒ¹é…çš„æ–‡ä»¶ï¼š{filename}ï¼ˆstates: {len(states)}, actions: {len(actions)}ï¼‰")
                    continue

                # æ·»åŠ åˆ°åˆ—è¡¨
                all_states.append(states)
                all_actions.append(actions)
                print(f"âœ… åŠ è½½æˆåŠŸï¼š{filename}ï¼ˆæ•°æ®é‡ï¼š{len(states)} æ¡ï¼‰")

            except Exception as e:
                # æ•è·å•ä¸ªæ–‡ä»¶åŠ è½½é”™è¯¯ï¼Œä¸å½±å“æ•´ä½“æµç¨‹
                print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥ï¼š{filename}ï¼Œé”™è¯¯ï¼š{str(e)}")
                continue

    # æ£€æŸ¥æ˜¯å¦åŠ è½½åˆ°æœ‰æ•ˆæ•°æ®
    if not all_states or not all_actions:
        raise ValueError("æœªåŠ è½½åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®ï¼è¯·æ£€æŸ¥ data ç›®å½•ä¸‹çš„ .npz æ–‡ä»¶")

    # åˆå¹¶æ‰€æœ‰ numpy æ•°ç»„ï¼ˆæŒ‰è¡Œæ‹¼æ¥ï¼Œaxis=0ï¼‰
    merged_states_np = np.concatenate(all_states, axis=0)
    merged_actions_np = np.concatenate(all_actions, axis=0)

    # è½¬æ¢ä¸º torch å¼ é‡ï¼ˆåŒ¹é…ä½ çš„åŸå§‹æ ¼å¼ï¼šstates=float32ï¼Œactions=longï¼‰
    merged_states = torch.tensor(merged_states_np, dtype=torch.float32)
    merged_actions = torch.tensor(merged_actions_np, dtype=torch.long)

    print(f"\nğŸ“Š æ•°æ®åˆå¹¶å®Œæˆï¼")
    print(f"æ€»æ•°æ®é‡ï¼š{len(merged_states)} æ¡")
    print(f"states å½¢çŠ¶ï¼š{merged_states.shape}ï¼ˆç»´åº¦ï¼š{merged_states.ndim}ï¼‰")
    print(f"actions å½¢çŠ¶ï¼š{merged_actions.shape}ï¼ˆç»´åº¦ï¼š{merged_actions.ndim}ï¼‰")

    return merged_states, merged_actions

def train_bc_model():
    """ç”¨æ”¶é›†çš„ä¸“å®¶æ•°æ®è®­ç»ƒBCæ¨¡å‹"""
    # åŠ è½½ä¸“å®¶æ•°æ®ï¼ˆç¡®ä¿å·²è¿è¡Œcollect_data.pyç”Ÿæˆexpert_data.npzï¼‰
    try:
        states, actions = load_all_npz_data()
        print(f"æˆåŠŸåŠ è½½ä¸“å®¶æ•°æ®ï¼š{len(states)} æ¡æ ·æœ¬")
    except FileNotFoundError:
        print("é”™è¯¯ï¼šæœªæ‰¾åˆ°expert_data.npzï¼è¯·å…ˆè¿è¡Œcollect_data.pyæ”¶é›†æ•°æ®")
        return

    # åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨
    model = BCPolicy()
    criterion = nn.CrossEntropyLoss()  # ç¦»æ•£åŠ¨ä½œç”¨äº¤å‰ç†µæŸå¤±
    optimizer = optim.Adam(model.parameters(), lr=1e-3)  # ä¼˜åŒ–å™¨

    # è®­ç»ƒå‚æ•°
    epochs = 500  # è®­ç»ƒè½®æ•°
    batch_size = 32  # æ‰¹æ¬¡å¤§å°

    print("\n=== å¼€å§‹è®­ç»ƒBCæ¨¡å‹ ===")
    for epoch in range(epochs):
        total_loss = 0.0
        # æ‰¹æ¬¡è¿­ä»£è®­ç»ƒ
        for i in range(0, len(states), batch_size):
            batch_states = states[i:i+batch_size]
            batch_actions = actions[i:i+batch_size]

            # å‰å‘ä¼ æ’­ï¼šé¢„æµ‹åŠ¨ä½œ
            logits = model(batch_states)
            loss = criterion(logits, batch_actions)

            # åå‘ä¼ æ’­ï¼šæ›´æ–°å‚æ•°
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item() * len(batch_states)

        # è®¡ç®—æ¯è½®å¹³å‡æŸå¤±
        avg_loss = total_loss / len(states)
        print(f"Epoch {epoch+1:2d}/{epochs} | Average Loss: {avg_loss:.4f}")

    # ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹
    torch.save(model.state_dict(), "model/bc_policy_230.pth")
    print("\næ¨¡å‹è®­ç»ƒå®Œæˆï¼å·²ä¿å­˜ä¸º model/bc_policy_230.pth")

if __name__ == "__main__":
    train_bc_model()