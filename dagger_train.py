import torch
import numpy as np
from snake_env import SnakeEnv
from train_bc import BCPolicy, train_bc_model  # å¤ç”¨BCæ¨¡å‹å’Œè®­ç»ƒå‡½æ•°
import pygame

def expert_annotator(state, env):
    """
    ä¸“å®¶æ ‡æ³¨å™¨ï¼šåªå“åº”æ–¹å‘é”®å’ŒQé”®ï¼Œå¿½ç•¥æ‰€æœ‰é¼ æ ‡äº‹ä»¶
    åŠŸèƒ½ï¼šæ ‡æ³¨å½“å‰çŠ¶æ€çš„æœ€ä¼˜åŠ¨ä½œï¼ŒQé”®ç¡®è®¤ï¼Œæ–¹å‘é”®é€‰æ‹©
    """
    print("\n=== ä¸“å®¶æ ‡æ³¨ ===")
    print("æ“ä½œè¯´æ˜ï¼šæ–¹å‘é”®é€‰æ‹©åŠ¨ä½œ â†’ Qé”®ç¡®è®¤æ ‡æ³¨ï¼ˆä»…å“åº”å­—æ¯Qå’Œæ–¹å‘é”®ï¼Œå¿½ç•¥é¼ æ ‡ï¼‰")
    action = None

    # ä¿®å¤ï¼šæ¸²æŸ“å®Œæ•´æ¸¸æˆçŠ¶æ€ï¼ˆè›‡èº«+é£Ÿç‰©ï¼‰ï¼Œç¡®ä¿æ ‡æ³¨åˆ¤æ–­å‡†ç¡®
    temp_screen = pygame.display.set_mode((400, 400))
    pygame.display.set_caption("ä¸“å®¶æ ‡æ³¨ - ä»…å“åº”Qé”®å’Œæ–¹å‘é”®")

    # æ¸²æŸ“å½“å‰çŠ¶æ€ï¼ˆå®Œæ•´è›‡èº«+é£Ÿç‰©ï¼‰
    def render_state():
        temp_screen.fill((0, 0, 0))  # é»‘è‰²èƒŒæ™¯
        # ç”»å®Œæ•´è›‡èº«ï¼ˆè€Œéä»…è›‡å¤´ï¼‰
        for segment in env.snake:
            pygame.draw.rect(temp_screen, (0, 255, 0), (segment[0], segment[1], 19, 19))
        # ç”»é£Ÿç‰©
        pygame.draw.rect(temp_screen, (255, 0, 0), (env.food[0], env.food[1], 19, 19))
        pygame.display.flip()  # å¼ºåˆ¶åˆ·æ–°ç”»é¢

    render_state()

    while True:
        # éå†æ‰€æœ‰äº‹ä»¶ï¼Œä½†åªå¤„ç†é”®ç›˜äº‹ä»¶ï¼Œå¿½ç•¥é¼ æ ‡äº‹ä»¶
        for event in pygame.event.get():
            # 3. ä»…å“åº”é”®ç›˜æŒ‰ä¸‹äº‹ä»¶ï¼ˆKEYDOWNï¼‰
            # print(f"event.type11 = {event.type}")
            # print(f"pygame.KEYDOWN11 = {pygame.KEYDOWN}")
            if event.type == pygame.KEYDOWN:
                print(f"event.type = {event.type}")
                print(f"pygame.KEYDOWN = {pygame.KEYDOWN}")

                # 1. å¿½ç•¥æ‰€æœ‰é¼ æ ‡äº‹ä»¶ï¼ˆç›´æ¥è·³è¿‡ï¼‰
                if event.type in [pygame.MOUSEBUTTONDOWN, pygame.MOUSEBUTTONUP, pygame.MOUSEMOTION]:
                    continue  # é¼ æ ‡äº‹ä»¶ä¸åšä»»ä½•å¤„ç†

                # 2. åªå¤„ç†é”®ç›˜äº‹ä»¶å’Œçª—å£å…³é—­äº‹ä»¶
                if event.type == pygame.QUIT:
                    pygame.quit()
                    exit("ç”¨æˆ·å…³é—­çª—å£ï¼Œç¨‹åºé€€å‡º")

                # è°ƒè¯•è¾“å‡ºï¼šä»…æ‰“å°é”®ç›˜äº‹ä»¶å…³é”®ä¿¡æ¯
                print(f"é”®ç›˜äº‹ä»¶ - event.key={event.key}, Qé”®æ ‡å‡†å€¼={pygame.K_q}")

                # åªå“åº” Qé”® å’Œ æ–¹å‘é”®ï¼Œå…¶ä»–å­—æ¯/æŒ‰é”®å¿½ç•¥
                if event.key == 49:  # æŒ‰1 ç¡®è®¤ ä»…å“åº”Qé”®ï¼ˆå¤§å°å†™å…¼å®¹ï¼Œå› pygame.K_qåŒ…å«å°å†™ï¼‰
                    if action is not None:
                        pygame.display.quit()
                        print(f"âœ… æ ‡æ³¨ç¡®è®¤ï¼šåŠ¨ä½œ={action}ï¼ˆ0=ä¸Šï¼Œ1=ä¸‹ï¼Œ2=å·¦ï¼Œ3=å³ï¼‰")
                        return action
                    else:
                        print("âŒ è¯·å…ˆæŒ‰æ–¹å‘é”®é€‰æ‹©åŠ¨ä½œï¼")
                elif event.key == pygame.K_UP:  # ä¸Šæ–¹å‘é”®
                    action = 0
                    print("å½“å‰é€‰æ‹©ï¼šä¸Šï¼ˆ0ï¼‰")
                    render_state()  # é€‰æ‹©ååˆ·æ–°ç”»é¢
                elif event.key == pygame.K_DOWN:  # ä¸‹æ–¹å‘é”®
                    action = 1
                    print("å½“å‰é€‰æ‹©ï¼šä¸‹ï¼ˆ1ï¼‰")
                    render_state()
                elif event.key == pygame.K_LEFT:  # å·¦æ–¹å‘é”®
                    action = 2
                    print("å½“å‰é€‰æ‹©ï¼šå·¦ï¼ˆ2ï¼‰")
                    render_state()
                elif event.key == pygame.K_RIGHT:  # å³æ–¹å‘é”®
                    action = 3
                    print("å½“å‰é€‰æ‹©ï¼šå³ï¼ˆ3ï¼‰")
                    render_state()
                else:
                    # å…¶ä»–æŒ‰é”®ï¼ˆå¦‚Aã€Bã€ç©ºæ ¼ç­‰ï¼‰ç›´æ¥å¿½ç•¥ï¼Œä¸æ‰“å°ã€ä¸å“åº”
                    pass

            # æŒç»­åˆ·æ–°ç”»é¢ï¼ˆé˜²æ­¢çª—å£å¡æ­»ï¼‰
            render_state()
            pygame.time.Clock().tick(30)  # 30FPSç¡®ä¿äº‹ä»¶å“åº”æµç•…

def dagger_iteration(n_iter=3):
    """
    DAGGERè¿­ä»£æµç¨‹ï¼ˆä¿®å¤çŠ¶æ€è®°å½•é”™è¯¯ï¼Œå¿½ç•¥é¼ æ ‡äº‹ä»¶ï¼‰
    """
    # åŠ è½½åˆå§‹ä¸“å®¶æ•°æ®ï¼ˆç”¨æˆ·æŒ‡å®šçš„ expert_data0.npzï¼‰
    try:
        data = np.load("expert_data0.npz")
        states = list(data["states"])
        actions = list(data["actions"])
        print(f"âœ… åŠ è½½åˆå§‹ä¸“å®¶æ•°æ®ï¼š{len(states)} æ¡æ ·æœ¬")
        if len(states) < 100:
            print("âš ï¸  è­¦å‘Šï¼šåˆå§‹æ•°æ®é‡è¿‡å°‘ï¼ˆå»ºè®®â‰¥500æ¡ï¼‰ï¼Œå¯èƒ½å½±å“è®­ç»ƒæ•ˆæœ")
    except FileNotFoundError:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° expert_data0.npzï¼è¯·å…ˆè¿è¡Œ collect_data.py æ”¶é›†åˆå§‹ä¸“å®¶æ•°æ®")
        return

    # åˆå§‹åŒ–BCæ¨¡å‹ï¼ˆé¦–æ¬¡è®­ç»ƒå‰ç”¨åˆå§‹æ•°æ®è®­ç»ƒï¼‰
    print("\n=== é¦–æ¬¡è®­ç»ƒåˆå§‹BCæ¨¡å‹ ===")
    train_bc_model()  # å¤ç”¨è®­ç»ƒå‡½æ•°
    model = BCPolicy()
    model.load_state_dict(torch.load("bc_policy.pth"))  # åŠ è½½åˆå§‹è®­ç»ƒåçš„æ¨¡å‹
    model.eval()

    for iter in range(n_iter):
        print(f"\n=== DAGGER è¿­ä»£ {iter+1}/{n_iter} ===")
        new_states = []
        new_actions = []
        env = SnakeEnv()
        state = env.reset()
        done = False
        step_count = 0  # é™åˆ¶æœ€å¤§æ­¥æ•°ï¼Œé¿å…æ— é™å¾ªç¯
        eat_food_num = 0

        while not done and step_count < 500:
            step_count += 1
            # æ¨¡å‹é¢„æµ‹åŠ¨ä½œ
            with torch.no_grad():
                state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)
                logits = model(state_tensor)
                model_action = torch.argmax(logits, dim=1).item()

            # æ‰§è¡ŒåŠ¨ä½œï¼Œè·å–ä¸‹ä¸€ä¸ªçŠ¶æ€
            next_state, _, done = env.step(model_action)
            # é‡ç½®è®¡æ•°
            if env.eat_food_num != eat_food_num:
                step_count = 0
                eat_food_num = env.eat_food_num

            # ä¿®å¤ï¼šè®°å½•æ¨¡å‹å†³ç­–æ—¶çš„åŸå§‹çŠ¶æ€ï¼ˆè€Œéæ‰§è¡Œåçš„next_stateï¼‰ï¼Œæ ‡æ³¨æ›´å‡†ç¡®
            new_states.append(state)

            # ä¸“å®¶æ ‡æ³¨ï¼ˆåªå“åº”Qé”®å’Œæ–¹å‘é”®ï¼Œå¿½ç•¥é¼ æ ‡ï¼‰
            expert_action = expert_annotator(state, env)
            new_actions.append(expert_action)

            # æ›´æ–°çŠ¶æ€
            state = next_state

        # è¿‡æ»¤æ— æ•ˆæ•°æ®ï¼ˆç¡®ä¿çŠ¶æ€å’ŒåŠ¨ä½œæ•°é‡ä¸€è‡´ï¼‰
        valid_len = min(len(new_states), len(new_actions))
        new_states = new_states[:valid_len]
        new_actions = new_actions[:valid_len]

        # æ‰©å……æ•°æ®é›†
        states.extend(new_states)
        actions.extend(new_actions)
        print(f"âœ… è¿­ä»£{iter+1}å®Œæˆï¼šæ–°å¢ {valid_len} æ¡æ•°æ®ï¼Œæ€»æ•°æ®é‡ {len(states)}")

        # ä¿å­˜æ‰©å……åçš„æ•°æ®é›†
        np.savez("expert_data_dagger.npz", states=np.array(states), actions=np.array(actions))
        np.savez(f"expert_data_dagger_iter{iter+1}.npz", states=np.array(states), actions=np.array(actions))

        # é‡æ–°è®­ç»ƒBCæ¨¡å‹
        print(f"\n=== è¿­ä»£{iter+1}ï¼šé‡æ–°è®­ç»ƒBCæ¨¡å‹ ===")
        train_bc_model()

        # åŠ è½½é‡æ–°è®­ç»ƒåçš„æ¨¡å‹ï¼ˆç”¨äºä¸‹ä¸€è½®è¿­ä»£ï¼‰
        model.load_state_dict(torch.load("bc_policy.pth"))
        model.eval()

    print("\nğŸ‰ DAGGERæ‰€æœ‰è¿­ä»£å®Œæˆï¼æœ€ç»ˆæ•°æ®é›†ï¼šexpert_data_dagger.npzï¼Œæœ€ç»ˆæ¨¡å‹ï¼šbc_policy.pth")

if __name__ == "__main__":
    # åˆå§‹åŒ–Pygameï¼ˆå¿…é¡»è°ƒç”¨ï¼Œå¦åˆ™é”®ç›˜äº‹ä»¶æ— æ³•å“åº”ï¼‰
    pygame.init()
    try:
        dagger_iteration(n_iter=3)
    finally:
        # ç¨‹åºç»“æŸåæ¸…ç†Pygameèµ„æº
        pygame.quit()
        print("ğŸ”š ç¨‹åºæ­£å¸¸é€€å‡ºï¼ŒPygameèµ„æºå·²é‡Šæ”¾")